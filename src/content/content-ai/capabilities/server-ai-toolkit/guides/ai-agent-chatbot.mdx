---
title: AI agent chatbot
meta:
  title: AI agent chatbot | Tiptap Content AI
  description: Build a server-side AI agent that can read and edit Tiptap documents using the Server AI Toolkit and Vercel AI SDK.
  category: Content AI
---

import { CodeDemo } from '@/components/CodeDemo'
import { Callout } from '@/components/ui/Callout'
import { Requirements, RequirementItem } from '@/components/Requirements'

<Requirements>
  <RequirementItem label="1. Get access">
    Access the Server AI Toolkit by applying for early access.{' '}
    <a href="https://tiptap.dev/contact-sales?form=ai-toolkit">Contact our team</a>.
  </RequirementItem>
  <RequirementItem label="2. Access the private registry">
    The Server AI Toolkit is published in Tiptap's private npm registry. Authenticate to Tiptap's
    private npm registry by following the [setup guide](/guides/pro-extensions).
  </RequirementItem>
  <RequirementItem label="3. Install the extension">
    Install the package from the private registry using npm or your preferred package manager.
  </RequirementItem>
</Requirements>

Build a server-side AI agent chatbot that can read and edit Tiptap documents. The AI runs on the server and edits documents stored in Tiptap Cloud.

<CodeDemo
  path=""
  isLarge
  isScrollable
  src="https://ai-toolkit-demos.vercel.app/server-ai-toolkit"
/>

## Tech stack

- [React](https://react.dev/) + [Next.js](https://nextjs.org/)
- [AI SDK by Vercel](https://ai-sdk.dev/) + [OpenAI](https://openai.com/) models
- [Tiptap Collaboration](https://tiptap.dev/docs/collaboration/getting-started/overview) for real-time sync
- Server AI Toolkit

## Installation

Create a [Next.js](https://nextjs.org/) project:

```bash
npx create-next-app@latest ai-agent-chatbot
```

Install the core Tiptap packages and the [Vercel AI SDK](https://ai-sdk.dev/) for Anthropic:

```bash
npm install @tiptap/react @tiptap/starter-kit @tiptap/extension-collaboration ai @ai-sdk/react @ai-sdk/anthropic yjs
```

Install the Tiptap Collaboration provider:

<Callout title="Pro package" variant="hint">
  The Collaboration provider is a pro package. Before installation, set up access to the private NPM
  registry by following the [private registry guide](/guides/pro-extensions).
</Callout>

```bash
npm install @tiptap-pro/provider
```

Install the Server AI Toolkit and the server tool definitions for the Vercel AI SDK:

```bash
npm install @tiptap-pro/server-ai-toolkit @tiptap-pro/ai-toolkit-ai-sdk
```

## Client-side setup

Create a client-side React component that renders the Tiptap Editor connected to Tiptap Collaboration and a simple chat UI.

```tsx
// app/page.tsx
'use client'

import { useChat } from '@ai-sdk/react'
import { Collaboration } from '@tiptap/extension-collaboration'
import { type Editor, EditorContent, useEditor } from '@tiptap/react'
import StarterKit from '@tiptap/starter-kit'
import { getSchemaAwarenessData } from '@tiptap-pro/server-ai-toolkit'
import { TiptapCollabProvider } from '@tiptap-pro/provider'
import { DefaultChatTransport, lastAssistantMessageIsCompleteWithToolCalls } from 'ai'
import { useCallback, useEffect, useRef, useState } from 'react'
import * as Y from 'yjs'

const doc = new Y.Doc()

export default function Page() {
  const providerRef = useRef<TiptapCollabProvider | null>(null)
  const editorRef = useRef<Editor | null>(null)

  const connectToCollaboration = useCallback(async () => {
    try {
      const { token, appId } = await getTiptapCloudCredentials()

      if (!providerRef.current) {
        providerRef.current = new TiptapCollabProvider({
          appId,
          token,
          user: 'user1',
          name: 'my-document',
          document: doc,
        })
      }
    } catch (error) {
      console.error('Failed to connect to collaboration:', error)
    }
  }, [])

  useEffect(() => {
    connectToCollaboration()

    return () => {
      if (providerRef.current) {
        providerRef.current.destroy()
        providerRef.current = null
      }
    }
  }, [connectToCollaboration])

  const editor = useEditor({
    immediatelyRender: false,
    extensions: [
      StarterKit.configure({ undoRedo: false }),
      Collaboration.configure({
        document: doc,
      }),
    ],
  })

  editorRef.current = editor

  const { messages, sendMessage } = useChat({
    transport: new DefaultChatTransport({
      api: '/api/chat',
      body: () => ({
        schemaAwarenessData: editorRef.current ? getSchemaAwarenessData(editorRef.current) : null,
      }),
    }),
    sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls,
  })

  const [input, setInput] = useState('Replace the last paragraph with a short story about Tiptap')

  if (!editor) return null

  return (
    <div>
      <EditorContent editor={editor} />
      {messages?.map((message) => (
        <div key={message.id} style={{ whiteSpace: 'pre-wrap' }}>
          <strong>{message.role}</strong>
          <br />
          {message.parts
            .filter((p) => p.type === 'text')
            .map((p) => p.text)
            .join('\n')}
        </div>
      ))}
      <form
        onSubmit={(e) => {
          e.preventDefault()
          sendMessage({ text: input })
          setInput('')
        }}
      >
        <input value={input} onChange={(e) => setInput(e.target.value)} />
      </form>
    </div>
  )
}
```

The component uses the `useChat` hook from the Vercel AI SDK to call the API endpoint and manage the chat conversation. It sends the schema awareness data to the server with each request.

## Server-side API endpoint

Create an API endpoint that uses the Server AI Toolkit to execute tool calls from the AI model:

```ts
// app/api/chat/route.ts
import { openai } from '@ai-sdk/openai'
import { getServerAiToolkit, TiptapCloudStorage } from '@tiptap-pro/server-ai-toolkit'
import { serverToolDefinitions } from '@tiptap-pro/ai-toolkit-ai-sdk'
import { convertToModelMessages, streamText, type UIMessage } from 'ai'

export async function POST(req: Request) {
  // Get the schema awareness data from the request body
  const { messages, schemaAwarenessData }: { messages: UIMessage[]; schemaAwarenessData: any } =
    await req.json()

  const serverAiToolkit = getServerAiToolkit({
    // The schema awareness data from the client-side
    schemaAwarenessData,
    // Pass the tool definitions to the AI model, in the format of your AI framework.
    tools: serverToolDefinitions(),
    // Connect to Tiptap Cloud to load and save documents
    storage: new TiptapCloudStorage({
      documentIdentifier: 'my-document',
      // Identify the changes as made by the AI.
      user: 'ai-user-1',
      appId: process.env.TIPTAP_CLOUD_APP_ID!,
      apiSecret: process.env.REST_API_SECRET!,
    }),
  })

  const result = streamText({
    model: openai('gpt-5.2'),
    // Allow the model to call tools up to 10 times
    stopWhen: stepCountIs(10),
    system: `You are an assistant that can edit rich text documents.
${serverAiToolkit.getSchemaAwarenessPrompt()}`,
    messages: convertToModelMessages(messages),
    // Provide the tools to the AI model.
    // They will execute whenever the model generates a tool call.
    tools: serverAiToolkit.getTools(),
  })

  return result.toUIMessageStreamResponse()
}
```

The endpoint creates a Server AI Toolkit instance with Tiptap Cloud storage and passes the tool definitions to the AI model. In the AI model response,
the AI model generates tool calls to read and/or edit the document.

When the AI model generates a tool call, the tool is automatically executed. When doing so,the Server AI Toolkit will automatically load and save the document to the Tiptap Cloud external storage defined in the `TiptapCloudStorage` instance.

## Environment variables

Add your Tiptap Cloud credentials and Anthropic API key as environment variables:

```sh
# .env
TIPTAP_CLOUD_APP_ID=your-app-id
REST_API_SECRET=your-rest-api-secret
OPENAI_API_KEY=your-openai-api-key
```

Get your Tiptap Cloud credentials from the [Tiptap Cloud dashboard](https://cloud.tiptap.dev/). Create an OpenAI API key in the [OpenAI Dashboard](https://platform.openai.com/api-keys).

## How it works

1. User types a message in the chat UI
2. Client sends the message and schema awareness data to the server
3. Server creates a Server AI Toolkit instance with Tiptap Cloud storage
4. AI model generates tool calls to read and edit the document
5. Server AI Toolkit executes the tool calls and updates the document in Tiptap Cloud
6. Changes sync to the client in real-time through Tiptap Collaboration
7. AI response streams back to the client

## End result

With additional CSS styles, the result is a simple but polished AI chatbot application:

<CodeDemo
  path=""
  isLarge
  isScrollable
  src="https://ai-toolkit-demos.vercel.app/server-ai-toolkit"
/>

See the [source code on GitHub](https://github.com/ueberdosis/ai-toolkit-demos).

## Next steps

- Learn about [storage options](/content-ai/capabilities/server-ai-toolkit/guides/storage) to use custom storage backends
- Explore the [primitives](/content-ai/capabilities/server-ai-toolkit/primitives/execute-tool) for more control over tool execution
- Check out the [configuration options](/content-ai/capabilities/server-ai-toolkit/configure) to customize the toolkit behavior
